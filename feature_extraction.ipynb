{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd1b31cb-2a60-42bf-9dbb-133a9fd52f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.models import Model\n",
    "import keras.utils as image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506301d5-a1ce-4416-b629-308226b8be20",
   "metadata": {},
   "source": [
    "## Extract the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef3eff-2a60-4d16-826e-a6d582efb79d",
   "metadata": {},
   "source": [
    "### LeakyReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62633755-e702-4ac9-aa17-2d04f625e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VGG16 model\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Replace ReLU with LeakyReLU\n",
    "# x = base_model.input\n",
    "# for layer in base_model.layers:\n",
    "#     if isinstance(layer, Conv2D):\n",
    "#         # Creates a new layer with the same configuration as the current layer, but without the activation function\n",
    "#         new_layer = Conv2D(\n",
    "#             filters=layer.filters,\n",
    "#             kernel_size=layer.kernel_size,\n",
    "#             strides=layer.strides,\n",
    "#             padding=layer.padding,\n",
    "#             activation=None,  \n",
    "#             name=layer.name\n",
    "#         )\n",
    "        \n",
    "#         new_layer.build(layer.input_shape)\n",
    "#         new_layer.set_weights(layer.get_weights())\n",
    "        \n",
    "#         x = new_layer(x)\n",
    "        \n",
    "#         # add LeakyReLU\n",
    "#         x = LeakyReLU(alpha=0.01)(x)\n",
    "        \n",
    "#     elif isinstance(layer, MaxPooling2D):\n",
    "#         x = layer(x)\n",
    "\n",
    "\n",
    "# # Add the full connection layer\n",
    "# x = Flatten()(x)  \n",
    "# x = Dense(4096)(x)\n",
    "# x = LeakyReLU(alpha=0.01)(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# # feature vector 4096\n",
    "# LeakyReLU_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "241478ba-8eb8-458b-9d36-cedb37d5ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images, preprocess, and extract features\n",
    "def extract_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "    img_preprocessed = preprocess_input(img_array_expanded)\n",
    "    features = model.predict(img_preprocessed)\n",
    "    return features.flatten()\n",
    "    #Extract the features and save the results to a CSV file\n",
    "\n",
    "def process_images_and_save_features(source_dir, output_csv_file, model):\n",
    "    data = {'filename': [], 'features': []}\n",
    "    \n",
    "    for subdir, _, files in os.walk(source_dir):\n",
    "        category_name = os.path.basename(subdir)\n",
    "        if files:\n",
    "            print(f\"Processing category: {category_name}\")\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                features = extract_features(img_path, model)\n",
    "                save_img_path = os.path.join('./images', subdir, file)\n",
    "                data['filename'].append(save_img_path)\n",
    "                data['features'].append(features)\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df['features'] = df['features'].apply(lambda x: ','.join(x.astype(str)))  # Converts an array of features to a comma-separated string\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "    print(\"Features are successfully saved to CSV.\")\n",
    "\n",
    "\n",
    "\n",
    "base_model = VGG16(weights='imagenet', input_shape=(224, 224, 3))\n",
    "intermediate_layer_model = keras.Model(inputs=base_model.input,\n",
    "                                       outputs=base_model.get_layer(\"fc1\").output)\n",
    "\n",
    "source_directory = './after-images'\n",
    "output_csv_file = 'features_database.csv'\n",
    "process_images_and_save_features(source_directory, output_csv_file, intermediate_layer_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fffcd44-9218-47d5-b3e9-f10f53389fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename  \\\n",
      "0  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "1  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "2  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "3  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "4  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "5  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "6  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "7  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "8  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "9  ./after-images\\001.Black_footed_Albatross\\Blac...   \n",
      "\n",
      "                                            features  \n",
      "0  -0.32282764,-0.33388615,-0.3026956,-0.16015178...  \n",
      "1  -0.5151883,-0.40601066,-0.2200102,-0.104522504...  \n",
      "2  -0.2909797,-0.3831334,-0.105868734,-0.16712645...  \n",
      "3  -0.2644592,-0.3867885,-0.20360933,-0.03952134,...  \n",
      "4  -0.5415482,-0.27620023,-0.35882914,-0.24081586...  \n",
      "5  -0.23514183,-0.41969904,-0.05220923,-0.3252513...  \n",
      "6  -0.08721257,-0.12609817,-0.106309496,-0.061548...  \n",
      "7  -0.7217677,-0.6205677,-0.8334547,-0.99556875,-...  \n",
      "8  -0.27691224,-0.19103773,-0.18751454,-0.0517882...  \n",
      "9  -0.3095441,-0.3278256,-0.48130435,-0.23209035,...  \n",
      "              0             1             2             3             4      \\\n",
      "count  11788.000000  11788.000000  11788.000000  11788.000000  11788.000000   \n",
      "mean       0.731409      0.602694      0.683120      0.961918      3.279386   \n",
      "std        5.564076      6.276601      6.507439      4.569966     10.046069   \n",
      "min       -1.379244     -1.435127     -1.431400     -1.965343     -1.292806   \n",
      "25%       -0.362399     -0.408150     -0.436336     -0.252177     -0.161804   \n",
      "50%       -0.234644     -0.283627     -0.297356     -0.138668     -0.070743   \n",
      "75%       -0.132818     -0.181259     -0.183556     -0.052774     -0.001010   \n",
      "max      143.444080    166.874020    144.698880     83.510840    134.208280   \n",
      "\n",
      "              5             6             7             8             9      \\\n",
      "count  11788.000000  11788.000000  11788.000000  11788.000000  11788.000000   \n",
      "mean       0.731693      0.034570      4.227243     -0.039700     -0.124438   \n",
      "std        5.769143      2.525409     13.621696      4.416542      2.247839   \n",
      "min       -1.309144     -1.792686     -1.201060     -2.082143     -1.592144   \n",
      "25%       -0.332362     -0.338315     -0.252946     -0.565114     -0.414790   \n",
      "50%       -0.218826     -0.208030     -0.136942     -0.364452     -0.275349   \n",
      "75%       -0.130892     -0.116680     -0.027749     -0.229972     -0.173184   \n",
      "max      147.914960     78.570496    179.167340    250.414100     72.709900   \n",
      "\n",
      "       ...         25078         25079         25080         25081  \\\n",
      "count  ...  11788.000000  11788.000000  11788.000000  11788.000000   \n",
      "mean   ...      8.591773      0.584644      7.034007      1.508970   \n",
      "std    ...     15.446287      3.772107     18.021924      7.621363   \n",
      "min    ...     -1.957217     -1.143441     -1.185841     -1.664968   \n",
      "25%    ...     -0.212449     -0.274360     -0.215719     -0.345858   \n",
      "50%    ...     -0.039627     -0.172520     -0.075028     -0.227942   \n",
      "75%    ...     12.505304     -0.095707      4.924899     -0.118576   \n",
      "max    ...    129.714770     53.010770    225.764280    132.207020   \n",
      "\n",
      "              25082         25083         25084         25085         25086  \\\n",
      "count  11788.000000  11788.000000  11788.000000  11788.000000  11788.000000   \n",
      "mean       0.518246      1.034056      1.099079      0.237006      3.396427   \n",
      "std        5.117369      5.752239      6.469443      4.356730      8.011964   \n",
      "min       -1.751928     -1.051159     -2.041701     -1.365238     -0.913897   \n",
      "25%       -0.494712     -0.271921     -0.414139     -0.419141     -0.136599   \n",
      "50%       -0.292636     -0.161336     -0.253112     -0.279240     -0.045996   \n",
      "75%       -0.140188     -0.068747     -0.131064     -0.165550      3.063736   \n",
      "max      103.824090    112.014940    122.398674    161.551090    126.337990   \n",
      "\n",
      "              25087  \n",
      "count  11788.000000  \n",
      "mean       0.663629  \n",
      "std        4.756956  \n",
      "min       -1.295487  \n",
      "25%       -0.335159  \n",
      "50%       -0.207660  \n",
      "75%       -0.101798  \n",
      "max      116.065605  \n",
      "\n",
      "[8 rows x 25088 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('LeakyReLU_features.csv')\n",
    "\n",
    "print(df.head(10))\n",
    "\n",
    "# Analyze statistical data for features, such as maximum, minimum, and average values\n",
    "feature_stats = df['features'].apply(lambda x: pd.Series([float(i) for i in x.split(',')]))\n",
    "print(feature_stats.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4fd9f",
   "metadata": {},
   "source": [
    "## Apply Approximate Nearest Neighbor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0973d1a-1f7a-4df2-bc24-3eb6b21605ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LeakyReLU_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df185725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        -0.14224967,-0.070818335,2.1476192,1.1205393,-...\n",
      "1        -0.3246294,-0.3124694,27.85961,54.828472,9.991...\n",
      "2        -0.18895955,-0.13565785,-0.039182447,8.250661,...\n",
      "3        -0.17739522,-0.22490333,-0.16277212,3.9561818,...\n",
      "4        -0.13278978,-0.3863413,4.439764,16.744944,-0.0...\n",
      "                               ...                        \n",
      "11783    0.48664144,26.14469,-0.08949319,-0.17218028,-0...\n",
      "11784    -0.20380531,-0.3805666,-0.110192865,10.370926,...\n",
      "11785    11.866622,13.224884,18.278954,11.173217,-0.141...\n",
      "11786    -0.27159083,-0.20956694,-0.024098996,-0.023456...\n",
      "11787    -0.68216264,-0.06175893,-0.20084643,16.13593,-...\n",
      "Name: features, Length: 11788, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "619da3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14224967 -0.07081833  2.1476192  ... -0.2711366   2.5553672\n",
      "  -0.04680335]\n",
      " [-0.3246294  -0.3124694  27.85961    ... -0.16064289 -0.29520825\n",
      "  19.332577  ]\n",
      " [-0.18895955 -0.13565785 -0.03918245 ...  8.794187   10.094434\n",
      "   1.8475256 ]\n",
      " [-0.17739522 -0.22490333 -0.16277212 ... -0.10267443 -0.13243131\n",
      "  35.22717   ]\n",
      " [-0.13278978 -0.3863413   4.439764   ... -0.31834787 -0.12048921\n",
      "  -0.16350059]]\n",
      "11788\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "features_df = df['features'].to_numpy()\n",
    "features_all = []\n",
    "for feat in features_df:\n",
    "    feat = feat.split(',')\n",
    "    feat = [float(f) for f in feat]\n",
    "    features_all.append(feat)\n",
    "features_all = np.array(features_all)\n",
    "print(features_all[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b04883f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n"
     ]
    }
   ],
   "source": [
    "def extract_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "    img_preprocessed = preprocess_input(img_array_expanded)\n",
    "    features = model.predict(img_preprocessed)\n",
    "    return features.flatten()\n",
    "\n",
    "root = \"./test_img/trial4\"\n",
    "files = os.listdir(root)\n",
    "features_q = []\n",
    "for f in files:\n",
    "    path = os.path.join(root, f)\n",
    "    if path.endswith(('.png', '.jpg')):\n",
    "        feat = extract_features(path, intermediate_layer_model)\n",
    "        features_q.append(feat)\n",
    "\n",
    "features_q = np.array(features_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19e0db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1145682  4.4280157  9.126083   ... 0.         0.         0.93021107]]\n"
     ]
    }
   ],
   "source": [
    "# query_vector = np.max(features_q, axis=0).reshape((1, 4096))\n",
    "# print(query_vector.shape)\n",
    "query_vector = features_q[2].reshape((1, 4096))\n",
    "print(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dbfe0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = features_all.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for similarity\n",
    "index.add(features_all[:10])  # Add the dataset to the index\n",
    "\n",
    "# Perform the search\n",
    "k = 5  # Number of nearest neighbors to find\n",
    "D, I = index.search(query_vector, k)  # D is the distance, I is the indices of the nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecd96886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 6 5 0 4]]\n",
      "[[270571.78 360135.4  459409.   465120.44 631355.1 ]]\n",
      "./after-images\\001.Black_footed_Albatross\\Black_Footed_Albatross_0010_796097.jpg\n",
      "./after-images\\001.Black_footed_Albatross\\Black_Footed_Albatross_0008_796083.jpg\n",
      "./after-images\\001.Black_footed_Albatross\\Black_Footed_Albatross_0007_796138.jpg\n",
      "./after-images\\001.Black_footed_Albatross\\Black_Footed_Albatross_0001_796111.jpg\n",
      "./after-images\\001.Black_footed_Albatross\\Black_Footed_Albatross_0006_796065.jpg\n"
     ]
    }
   ],
   "source": [
    "print(I)\n",
    "print(D)\n",
    "print(df.iat[I[0,0], 0])\n",
    "print(df.iat[I[0,1], 0])\n",
    "print(df.iat[I[0,2], 0])\n",
    "print(df.iat[I[0,3], 0])\n",
    "print(df.iat[I[0,4], 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
